{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 12\n",
      "Shape of X: (500, 4)\n",
      "\n",
      "data type of X: Square_Feet           float64\n",
      "Garage_Size             int64\n",
      "Location_Score        float64\n",
      "Distance_to_Center    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Use pandas to load real_estate_dataset.csv\n",
    "df = pd.read_csv('real_estate_dataset.csv')\n",
    "\n",
    "# get the number of samples and features\n",
    "n_samples, n_features = df.shape\n",
    "\n",
    "print(f\"Number of columns: {n_features}\")\n",
    "\n",
    "# get the names of the coloumns\n",
    "columns = df.columns\n",
    "\n",
    "# save the column names to a file fir accessing later as a text file\n",
    "np.savetxt('columns.txt', columns, fmt='%s')\n",
    "\n",
    "# use only square_feet, garage_size, location_score, distance_to_center as features:\n",
    "X = df[['Square_Feet', 'Garage_Size', 'Location_Score', 'Distance_to_Center']]\n",
    "\n",
    "# use price as the target\n",
    "y = df['Price'].values\n",
    "\n",
    "print(f\"Shape of X: {X.shape}\\n\")\n",
    "print(f\"data type of X: {X.dtypes}\")\n",
    "\n",
    "#get the number of samples and features in X\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a linear model to predict price from the four features in X\n",
    "# make an array of coefs of the size of (n_features + 1), Initialise to 1.\n",
    "\n",
    "coefs = np.ones(n_features + 1)\n",
    "\n",
    "# predict the price for each sample in X\n",
    "predictions_bydefn = X @ coefs[1:] + coefs[0]\n",
    "\n",
    "# append a columns of ones to X\n",
    "X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "\n",
    "# predict the price for each sample in X\n",
    "predictions = X @ coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the predictions same? True\n"
     ]
    }
   ],
   "source": [
    "# see if all entries in predictions_bydefn and predictions are the same\n",
    "is_same = np.allclose(predictions_bydefn, predictions)\n",
    "print(f\"Are the predictions same? {is_same}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the two methods the same? True\n",
      "Size of errors: (500,)\n",
      "L2 norm of errors: 13297007.321853263\n",
      "L2 norm of relative errors: 22.35214323542266\n"
     ]
    }
   ],
   "source": [
    "# calculate the error using predictions and y\n",
    "errors = y - predictions\n",
    "\n",
    "# calculate the relative error\n",
    "relative_errors = errors / y\n",
    "\n",
    "# calculate the mean of squares of error using a loop\n",
    "loss_loop = 0\n",
    "for i in range(n_samples):\n",
    "    loss_loop += errors[i] ** 2\n",
    "\n",
    "loss_loop = loss_loop/n_samples\n",
    "\n",
    "# calculate the mean of squares of error using matrix operations\n",
    "loss_matrix = np.transpose(errors) @ errors / n_samples\n",
    "\n",
    "# check if the two methods give the same result\n",
    "is_diff = np.allclose(loss_loop, loss_matrix)\n",
    "print(f\"Are the two methods the same? {is_diff}\")\n",
    "\n",
    "# print the size of errors, and its L2 norm\n",
    "print(f\"Size of errors: {errors.shape}\")\n",
    "print(f\"L2 norm of errors: {np.linalg.norm(errors)}\")\n",
    "print(f\"L2 norm of relative errors: {np.linalg.norm(relative_errors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of errors_model: 2240271.803752977\n",
      "L2 norm of relative errors: 22.35214323542266\n"
     ]
    }
   ],
   "source": [
    "# What is my optimisation problem? \n",
    "# I want to find the coefficients that minimise the mean of squares of errors\n",
    "# This is called as Least Squares problem\n",
    "\n",
    "# Aside\n",
    "# Nu = f (Re, Pr); Nu = \\alpha Re^m Pr^n, we want to find \\alpha, m, n that best fit the data\n",
    "\n",
    "# Objective function: f(coefs) = 1/n_samples * \\sum_{i=1}^{n_samples} (y_i - \\sum_{j=0}^{n_features} coefs[j] * X[i, j])^2\n",
    "\n",
    "# What is a solution?\n",
    "# A solution is a set of coefficients that minimises the objective function\n",
    "\n",
    "# How do I find a solution?\n",
    "# By searching for the coeeficients at which the gradient of the objective function is zero\n",
    "# Or I can set the gradient of the objective function to zero and solve for the coefficients\n",
    "\n",
    "# write the loss_matrix in terms of data and coefs\n",
    "loss_matrix = (y - X @ coefs).T @ (y - X @ coefs) / n_samples\n",
    "\n",
    "# calculate the gradient of the loss with respect to coefs\n",
    "grad_matrix = -2/n_samples * X.T @ (y - X @ coefs)\n",
    "\n",
    "# we set grad_matrix to zero and solve for coefs\n",
    "# X.T @ y = X.T @ X @ coefs\n",
    "# X.T @ X @ coefs = X.T @ y  (This is called the normal equation)\n",
    "# coefs = (X.T @ X)^-1 @ X.T @ y\n",
    "\n",
    "coefs = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "# save coefs to a file for viewing later\n",
    "np.savetxt('coefs.txt', coefs)\n",
    "\n",
    "# calculate the predictions using the new coefs\n",
    "predictions_model = X @ coefs\n",
    "\n",
    "# calculate the errors using the new predictions\n",
    "errors = y - predictions_model\n",
    "\n",
    "# # calculate the relative errors\n",
    "# relative_errors = errors / y\n",
    "\n",
    "# print L2 norm of the errors_model\n",
    "print(f\"L2 norm of errors_model: {np.linalg.norm(errors)}\")\n",
    "# print L2 norm of the relative errors\n",
    "print(f\"L2 norm of relative errors: {np.linalg.norm(relative_errors)}\")\n",
    "\n",
    "# Use all the features in the dataset to build a linear model to predict price\n",
    "X = df.drop('Price', axis=1).values\n",
    "y = df['Price'].values\n",
    "\n",
    "# get the number of samples and features in X\n",
    "n_samples, n_features = X.shape\n",
    "print(f\"Number of samples, features: {n_samples, n_features}\")\n",
    "# solve the linear model using the normal equation\n",
    "X = np.hstack([np.ones((n_samples, 1)), X])\n",
    "coefs = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "# save coefs to a file names coefs_all.txt\n",
    "np.savetxt('coefs_all.txt', coefs, delimiter=',')\n",
    "\n",
    "\n",
    "### STUDY JACOBIAN AND HESSIAN. STUDY MATRIX CALCULUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of X.T @ X: 5\n",
      "Shape of Q: (500, 5)\n",
      "Shape of R: (5, 5)\n",
      "Shape of b: (5,)\n",
      "Shape of R: (5, 5)\n",
      "L2 norm of errors_svd: 2240271.803752977\n",
      "L2 norm of relative errors_svd: 4.32709776267726\n"
     ]
    }
   ],
   "source": [
    "# calculate the rank of X.T @ X\n",
    "rank_XTX = np.linalg.matrix_rank(X.T @ X)\n",
    "print(f\"Rank of X.T @ X: {rank_XTX}\")\n",
    "\n",
    "# solve the normal equation using matrix decomposition\n",
    "# QR FACTORISATION\n",
    "Q, R = np.linalg.qr(X)\n",
    "\n",
    "print(f\"Shape of Q: {Q.shape}\") # Q is orthogonal (study)\n",
    "print(f\"Shape of R: {R.shape}\")\n",
    "\n",
    "# write R to a file named R.csv\n",
    "np.savetxt('R.csv', R, delimiter=',')   # R is upper triangular\n",
    "\n",
    "# R*coefs = b\n",
    "\n",
    "sol =Q.T @ Q # identity matrix\n",
    "np.savetxt('sol.csv', sol, delimiter=',')\n",
    "\n",
    "# X = QR\n",
    "# X.T @ X = R.T @ Q.T @ Q @ R = R.T @ R\n",
    "# X.T @ y = R.T @ Q.T @ y\n",
    "# R.coefs = Q.T @ y\n",
    "\n",
    "b = Q.T @ y\n",
    "print(f\"Shape of b: {b.shape}\")\n",
    "print(f\"Shape of R: {R.shape}\")\n",
    "\n",
    "#coeffs_qr = np.linalg.inv(R) @ b\n",
    "\n",
    "# loop to solve R*coeffs = b using back substitution\n",
    "coeffs_qr_loop = np.zeros(n_features + 1)\n",
    "\n",
    "for i in range(n_features, -1, -1):\n",
    "    coeffs_qr_loop[i] = b[i]\n",
    "    for j in range(i+1, n_features + 1):\n",
    "        coeffs_qr_loop[i] -= R[i, j] * coeffs_qr_loop[j]\n",
    "\n",
    "    coeffs_qr_loop[i] = coeffs_qr_loop[i] / R[i, i]\n",
    "# coeffs_qr_loop = coeffs_qr_loop / np.diag(R)\n",
    "\n",
    "# save coeffs_qr_loop to a file named coeffs_qr_loop.csv\n",
    "np.savetxt('coeffs_qr_loop.csv', coeffs_qr_loop, delimiter=',')\n",
    "\n",
    "# Solve the normal equation using SVD\n",
    "U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "# X = U S V^T  (Note that these are transposes and inverses)\n",
    "\n",
    "# Eigen Decomposition of a square matrix\n",
    "# A = V D V^T\n",
    "# A^-1 = V D^-1 V^T\n",
    "# X * coeffs = y\n",
    "# A = X^T X\n",
    "\n",
    "# Normal Equation: X^T X * coeffs = X^T y\n",
    "# Xdagger = (X^T X)^-1 X^T \n",
    "\n",
    "# TO COMPLETE: CALCULATE THE COEFFS_SVD USING THE PSEUDO INVERSE OF X\n",
    "\n",
    "S_inverse = np.diag(1/S)\n",
    "coeffs_svd = Vt.T @ S_inverse @ U.T @ y\n",
    "\n",
    "# Calculate errors and predictions using the new coefs\n",
    "predictions_svd = X @ coeffs_svd\n",
    "errors_svd = y - predictions_svd\n",
    "\n",
    "# L2 norm of errors_svd\n",
    "print(f\"L2 norm of errors_svd: {np.linalg.norm(errors_svd)}\")\n",
    "\n",
    "# L2 norm of relative errors_svd\n",
    "relative_errors_svd = errors_svd / y\n",
    "print(f\"L2 norm of relative errors_svd: {np.linalg.norm(relative_errors_svd)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
